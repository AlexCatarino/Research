{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n", "<hr>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Predicting Future Prices With TensorFlow \n", "#### An example of TF model building, training, saving in the ObjectStore, and loading."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Import Libraries\n", "Let's start by importing the functionality we'll need to build the model, split the data, and serialize/unserialize the model for saving and loading."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "from sklearn.model_selection import train_test_split\n", "import json5\n", "from google.protobuf import json_format"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Gather & Prepare Data\n", "Let's retreive some intraday data for the SPY by making a History request."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["qb = QuantBook()\n", "spy = qb.AddEquity(\"SPY\").Symbol\n", "data = qb.History(spy, \n", "                  datetime(2020, 6, 22), \n", "                  datetime(2020, 6, 27), \n", "                  Resolution.Minute).loc[spy].close\n", "data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll use the last 5 closing prices of the SPY as inputs to our model. Here, we create a DataFrame containing this data."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["lookback = 5\n", "lookback_series = []\n", "for i in range(1, lookback + 1):\n", "    df = data.shift(i)[lookback:-1]\n", "    df.name = f\"close_-{i}\"\n", "    lookback_series.append(df)\n", "X = pd.concat(lookback_series, axis=1).reset_index(drop=True)\n", "X"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'd like the model to predict the closing price of the SPY 1 timestep into the future, so let's create a DataFrame containing this data."]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["Y = data.shift(-1)[lookback:-1].reset_index(drop=True)\n", "Y.plot(figsize=(16, 6))\n", "plt.title(\"SPY price 1 timestep in the future\")\n", "plt.xlabel(\"Time step\")\n", "plt.ylabel(\"Price\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, let's split the data into testing and training sets."]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["test_size = 0.33\n", "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle=False)\n", "print(f\"Train index: {X_train.index[0]}...{X_train.index[-1]}\")\n", "print(f\"Test index: {X_test.index[0]}...{X_test.index[-1]}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Define a Testing Method\n", "To test the model, we'll setup a method to plot test set predictions ontop of the SPY price."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["def test_model(sess, output, title, X):\n", "    prediction = sess.run(output, feed_dict={X: X_test})\n", "    prediction = prediction.reshape(prediction.shape[1], 1)\n", "\n", "    y_test.reset_index(drop=True).plot(figsize=(16, 6), label=\"Actual\")\n", "    plt.plot(prediction, label=\"Prediction\")\n", "    plt.title(title)\n", "    plt.xlabel(\"Time step\")\n", "    plt.ylabel(\"SPY Price\")\n", "    plt.legend()\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Manually Build the Model \n", "Let's build the neural network architecture by utilizing the TensorFlow library. Note how we name the input and output nodes so we can retreive them when loading the model from the ObjectStore."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["tf.reset_default_graph()\n", "sess = tf.Session()\n", "\n", "num_factors = X_test.shape[1]\n", "num_neurons_1 = 32\n", "num_neurons_2 = 16\n", "num_neurons_3 = 8\n", "\n", "X = tf.placeholder(dtype=tf.float32, shape=[None, num_factors], name='X')\n", "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n", "\n", "# Initializers\n", "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=1)\n", "bias_initializer = tf.zeros_initializer()\n", "\n", "# Hidden weights\n", "W_hidden_1 = tf.Variable(weight_initializer([num_factors, num_neurons_1]))\n", "bias_hidden_1 = tf.Variable(bias_initializer([num_neurons_1]))\n", "W_hidden_2 = tf.Variable(weight_initializer([num_neurons_1, num_neurons_2]))\n", "bias_hidden_2 = tf.Variable(bias_initializer([num_neurons_2]))\n", "W_hidden_3 = tf.Variable(weight_initializer([num_neurons_2, num_neurons_3]))\n", "bias_hidden_3 = tf.Variable(bias_initializer([num_neurons_3]))\n", "\n", "# Output weights\n", "W_out = tf.Variable(weight_initializer([num_neurons_3, 1]))\n", "bias_out = tf.Variable(bias_initializer([1]))\n", "\n", "# Hidden layer\n", "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n", "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n", "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n", "\n", "# Output layer\n", "output = tf.transpose(tf.add(tf.matmul(hidden_3, W_out), bias_out), name='outer')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll train the neural network by iteratively minimizing the mean squared difference between the model predictions and the actual SPY price."]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["loss = tf.reduce_mean(tf.squared_difference(output, Y))\n", "optimizer = tf.train.AdamOptimizer().minimize(loss)\n", "sess.run(tf.global_variables_initializer())\n", "\n", "batch_size = len(y_train) // 10\n", "epochs = 20\n", "for _ in range(epochs):\n", "    for i in range(0, len(y_train) // batch_size):\n", "        start = i * batch_size\n", "        batch_x = X_train[start:start + batch_size]\n", "        batch_y = y_train[start:start + batch_size]\n", "        sess.run(optimizer, feed_dict={X: batch_x, Y: batch_y})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To ensure the model we've built and trained is working, let's plot it's predictions on the test set."]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": [" test_model(sess, output, \"Test Set Results from Original Model\", X)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Save Model to the ObjectStore\n", "We first serialize the TensorFlow graph and weights to JSON format, then save these in the ObjectStore by using the `Save` method."]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["graph_definition = tf.compat.v1.train.export_meta_graph()\n", "json_graph = json_format.MessageToJson(graph_definition)\n", "\n", "def get_json_weights(sess):\n", "    weights = sess.run(tf.compat.v1.trainable_variables())\n", "    weights = [w.tolist() for w in weights]\n", "    weights_list = json5.dumps(weights)\n", "    return weights_list\n", "json_weights = get_json_weights(sess)\n", "sess.close()\n", "\n", "qb.ObjectStore.Save('graph', json_graph)\n", "qb.ObjectStore.Save('weights', json_weights)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Load Model from the ObjectStore\n", "Let's first retreive the JSON for the TensorFlow graph and weights that we saved in the ObjectStore."]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["json_graph = qb.ObjectStore.Read('graph')\n", "json_weights = qb.ObjectStore.Read('weights')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's restore the TensorFlow graph from JSON and select the input and output nodes."]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["tf.reset_default_graph()\n", "graph_definition = json_format.Parse(json_graph, tf.compat.v1.MetaGraphDef())\n", "sess = tf.Session()\n", "tf.compat.v1.train.import_meta_graph(graph_definition)\n", "X = tf.compat.v1.get_default_graph().get_tensor_by_name('X:0')\n", "output = tf.compat.v1.get_default_graph().get_tensor_by_name('outer:0')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To avoid retraining the model after loading, let's restore the weights."]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["weights = [np.asarray(x) for x in json5.loads(json_weights)]\n", "\n", "assign_ops = []\n", "feed_dict = {}\n", "vs = tf.compat.v1.trainable_variables()\n", "zipped_values = zip(vs, weights)\n", "for var, value in zipped_values:\n", "    value = np.asarray(value)\n", "    assign_placeholder = tf.placeholder(var.dtype, shape=value.shape)\n", "    assign_op = var.assign(assign_placeholder)\n", "    assign_ops.append(assign_op)\n", "    feed_dict[assign_placeholder] = value\n", "sess.run(assign_ops, feed_dict=feed_dict);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To ensure loading the model was successfuly, let's test the model."]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["test_model(sess, output, \"Test Set Results from Loaded Model\", X)\n", "sess.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Appendix\n", "Below are some helper methods to manage the ObjectStore keys. We can use these to validate the saving and loading is successful."]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["def get_ObjectStore_keys():\n", "    return [str(j).split(',')[0][1:] for _, j in enumerate(qb.ObjectStore.GetEnumerator())]\n", "\n", "def clear_ObjectStore():\n", "    for key in get_ObjectStore_keys():\n", "        qb.ObjectStore.Delete(key)"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["clear_ObjectStore()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2}