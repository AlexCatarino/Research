{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n", "<hr>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Predicting Future Prices With Keras\n", "#### An example of Keras model building, training, saving in the ObjectStore, and loading."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Import Libraries\n", "Let's start by importing the functionality we'll need to build the model  and serialize/unserialize the model for saving and loading"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["from tensorflow.keras import utils\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Dense, Flatten\n", "from tensorflow.keras.optimizers import RMSprop\n", "import json\n", "from keras.utils.generic_utils import serialize_keras_object "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Gather & Prepare Data\n", "Let's retreive some daily data for the SPY by making a History request."]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["qb = QuantBook()\n", "spy = qb.AddEquity('SPY')\n", "history = qb.History(qb.Securities.Keys, 360, Resolution.Daily)\n", "spy_hist = history.loc['SPY']\n", "spy_hist"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We create a function that prepares our data suitable for training and testing our Model. We use 5 steps of OHLCV data to predict the closing price of the bar right after. By tying this to a function, we increase clarity, as well as reusability, especially if we were to copy it into a class in a .py file."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# function to prepare our data for training our NN\n", "def prep_data(data, n_tsteps=5):\n", "    # n_tsteps is the number of time steps at and before time t we want to use\n", "    #   to predict the close price at time t + 1\n", "    \n", "    # this helps normalizes the data\n", "    df = data.pct_change()[1:]\n", "    \n", "    features = []\n", "    labels = []\n", "\n", "    for i in range(len(df)-n_tsteps):\n", "        input_data = df.iloc[i:i+n_tsteps].values\n", "        features.append(input_data)\n", "        label = df['close'].iloc[i+n_tsteps]\n", "        labels.append(label)\n", "\n", "    return np.array(features), np.array(labels)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Build the Model (Regression Neural Network)\n", "Let's build the neural network using Keras. We create a function that creates our Model, building up the input and output layers, and the layers Between. We tie this to a function for the same reason mentioned before."]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["def build_model():\n", "    model = Sequential([\n", "        # 5 input variables (OHLCV) by 5 time steps\n", "        Dense(10, input_shape=(5,5), activation='relu'),\n", "        Dense(10, activation='relu'),\n", "        # Flatten layer required because input shape is 2D\n", "        Flatten(),\n", "        # since we are performing regression, we only need 1 output node\n", "        Dense(1)\n", "    ])\n", "\n", "    model.compile(loss='mse',\n", "                optimizer=RMSprop(0.001),\n", "                metrics=['mae', 'mse'])\n", "    return model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll train the neural network by preparing our data with the function we defined earlier and feeding the result into our model"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"scrolled": true}, "outputs": [], "source": ["X, y = prep_data(spy_hist)\n", "model = build_model()\n", "\n", "# split data into training/testing sets\n", "X_train = X[:300]\n", "X_test = X[300:]\n", "y_train = y[:300]\n", "y_test = y[300:]\n", "\n", "model.fit(X_train, y_train, epochs=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Analyze Performance\n", "We then make predictions on the testing data set. We compare our Predicted Values with the Expected Values by plotting both to see if our Model has predictive power."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["y_hat = model.predict(X_test)\n", "df = pd.DataFrame({'y': y_test.flatten(), 'y_hat': y_hat.flatten()})\n", "df.plot(title='Model Performance: predicted vs actual %change in closing price')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Save the Model to ObjectStore\n", "We first serialize our model into a JSON string, then we save our model to ObjectStore. This way, the model doesn't need to be retrained, saving time and computational resources."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["model_key = 'spy_model'\n", "\n", "modelStr = json.dumps(serialize_keras_object(model))\n", "qb.ObjectStore.Save(model_key, modelStr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Load Model from the ObjectStore\n", "Let's first retreive the JSON for the Keras model that we saved in the ObjectStore, then restore our model from this JSON string"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["if qb.ObjectStore.ContainsKey(model_key):\n", "    modelStr = qb.ObjectStore.Read(model_key)\n", "    config = json.loads(modelStr)['config']\n", "    loaded_model = Sequential.from_config(config)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To ensure loading the model was successfuly, let's test the model by having it make predictions."]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["y_hat = loaded_model.predict(X_test)\n", "df = pd.DataFrame({'y': y_test.flatten(), 'y_hat': y_hat.flatten()})\n", "df.plot(title='Model Performance: predicted vs actual %change in closing price')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Appendix\n", "Below are some helper methods to manage the ObjectStore keys. We can use these to validate the saving and loading is successful."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["def get_ObjectStore_keys():\n", "    return [str(j).split(',')[0][1:] for _, j in enumerate(qb.ObjectStore.GetEnumerator())]\n", "\n", "def clear_ObjectStore():\n", "    for key in get_ObjectStore_keys():\n", "        qb.ObjectStore.Delete(key)"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["clear_ObjectStore()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2}
