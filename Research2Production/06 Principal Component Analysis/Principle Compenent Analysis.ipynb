{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Component Analysis\n",
    "Briefly stated, collinearity is the state of two independent variables being highly correlated. Unfortunately, collinearity can cause trouble when using regression models. One of the fundamental assumptions of Ordinary Least Squares regression is that the variables can't have a linear relationship. This problem is especially tricky when dealing with multiple variables in regression models where multicollinearity occurs. The presence of multicollinearity is a problem because the linear regression model cannot distinguish between the co-lineated variables. It may cause some variables to appear to be insignificant in the relationship when they really are - in other words, their \"weight\" is transferred to another, correlated value.\n",
    "\n",
    "Principal Component Analysis (PCA) a way of mapping the existing dataset into a new \"space\", where the dimensions of the new data are linearly-independent, orthogonal vectors. PCA eliminates the problem of multicollinearity. In addition to this, PCA gives us a way of identifying the dimensions of the data that contribute most to the variance of the data, meaning we can also use PCA to reduce the number of input variables in our regression model. We can use the PCA-transformed data to build a regression model, make predictions, and then map those predictions back into the original data \"space\" so that we have applicable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression, HuberRegressor, Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Import the Liquid ETF Universe helper methods\n",
    "from QuantConnect.Data.UniverseSelection import *\n",
    "from QuantConnect.Data.Custom.USTreasury import *\n",
    "\n",
    "# Initialize QuantBook and the US Treasuries ETFs\n",
    "qb = QuantBook()\n",
    "yieldCurve = qb.AddData(USTreasuryYieldCurveRate, \"USTYCR\", Resolution.Daily).Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiveyear</th>\n",
       "      <th>onemonth</th>\n",
       "      <th>oneyear</th>\n",
       "      <th>sevenyear</th>\n",
       "      <th>sixmonth</th>\n",
       "      <th>tenyear</th>\n",
       "      <th>thirtyyear</th>\n",
       "      <th>threemonth</th>\n",
       "      <th>threeyear</th>\n",
       "      <th>twentyyear</th>\n",
       "      <th>twomonth</th>\n",
       "      <th>twoyear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-29</th>\n",
       "      <td>-0.040816</td>\n",
       "      <td>-0.006536</td>\n",
       "      <td>-0.013072</td>\n",
       "      <td>-0.032051</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.030303</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>-0.006369</td>\n",
       "      <td>-0.041379</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>-0.020690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-30</th>\n",
       "      <td>-0.014184</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>-0.019868</td>\n",
       "      <td>-0.013245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>-0.004878</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>-0.014388</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>-0.007042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>-0.050360</td>\n",
       "      <td>-0.018868</td>\n",
       "      <td>-0.020270</td>\n",
       "      <td>-0.046980</td>\n",
       "      <td>-0.019108</td>\n",
       "      <td>-0.038217</td>\n",
       "      <td>-0.024510</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>-0.051095</td>\n",
       "      <td>-0.026596</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.056738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fiveyear  onemonth   oneyear  sevenyear  sixmonth   tenyear  \\\n",
       "time                                                                      \n",
       "2020-01-28  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "2020-01-29 -0.040816 -0.006536 -0.013072  -0.032051 -0.006329 -0.030303   \n",
       "2020-01-30 -0.014184  0.046053 -0.019868  -0.013245  0.000000 -0.018750   \n",
       "2020-01-31 -0.050360 -0.018868 -0.020270  -0.046980 -0.019108 -0.038217   \n",
       "2020-02-03  0.022727  0.000000  0.006897   0.021127  0.012987  0.019868   \n",
       "\n",
       "            thirtyyear  threemonth  threeyear  twentyyear  twomonth   twoyear  \n",
       "time                                                                           \n",
       "2020-01-28    0.000000    0.000000   0.000000    0.000000  0.000000  0.000000  \n",
       "2020-01-29   -0.023810   -0.006369  -0.041379   -0.030769 -0.012739 -0.020690  \n",
       "2020-01-30   -0.004878    0.006410  -0.014388   -0.005291  0.019355 -0.007042  \n",
       "2020-01-31   -0.024510   -0.012739  -0.051095   -0.026596 -0.006329 -0.056738  \n",
       "2020-02-03    0.010050    0.012903   0.030769    0.005464  0.000000  0.022556  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get history\n",
    "history = qb.History(yieldCurve, 100, Resolution.Daily)\n",
    "# Get prices and returns\n",
    "bonds = history.loc[yieldCurve].pct_change().ffill().fillna(value = 0).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "bonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure data for modeling - train for building the models, testing to make predictions with\n",
    "training = bonds.iloc[:len(bonds)-1].copy()\n",
    "testing = bonds.iloc[len(bonds)-1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implementation of the function in RegressionFunction.py but with some added plotting features\n",
    "def FitRegressionModel(pca, model, training, testing, alpha = False):    \n",
    "    estimators = []\n",
    "    Y_pred = []\n",
    "    Y_actual = []\n",
    "    X_training_proj = pca.transform(training)\n",
    "\n",
    "    # Iterate over all principle components:\n",
    "    for i in range(pca.n_components_):\n",
    "\n",
    "        # Here, we lag X compared to Y. X will be one time period behind Y\n",
    "        X = X_training_proj[:-1, i]\n",
    "        Y = X_training_proj[1:, i]\n",
    "        \n",
    "        Y_actual.append(Y)\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        if alpha:\n",
    "            test_range = np.arange(5)\n",
    "            param_grid = {\"alpha\": test_range}\n",
    "            grid_search = GridSearchCV(model,param_grid)\n",
    "            grid_search.fit(X, Y)\n",
    "            best_params = grid_search.best_params_\n",
    "        \n",
    "        est = model.fit(X, Y)\n",
    "        estimators.append(est)\n",
    "        Y_pred.append(model.predict(X))\n",
    "        print(\"Estimator {}: R2 = {:.3f}\\n\".format(i, model.score(X,Y)))\n",
    "    \n",
    "    Y_pred = np.array(Y_pred).transpose()\n",
    "    Y_actual = np.array(Y_actual).transpose()\n",
    "    \n",
    "    Y_actual_original_space = pca.inverse_transform(Y_actual)\n",
    "    Y_pred_original_space = pca.inverse_transform(Y_pred)\n",
    "\n",
    "    # Compute sum of squared error:\n",
    "    train_sse = np.sum((Y_pred_original_space - Y_actual_original_space)** 2)\n",
    "    print(f'Sum of squared error: {train_sse}\\n')\n",
    "    testing_proj = pca.transform(testing)\n",
    "    \n",
    "    testing_prediction = []\n",
    "    for i in range(pca.n_components_):\n",
    "        # Create a data row - remember our estimators have a constant, so we need that\n",
    "        row = [1, testing_proj[:,i]]\n",
    "        print(row)\n",
    "        row = np.reshape(row, (1, 2))\n",
    "        # Predict this row\n",
    "        p = model.predict(row)\n",
    "        # Transofrm the (1, 1) result into just a (1,), and append to our predictions\n",
    "\n",
    "        # Potential error here:\n",
    "        testing_prediction.append(p[0])  # If this errors, try p[0][0]\n",
    "        \n",
    "    predictions = pca.inverse_transform(testing_prediction)\n",
    "    pred_sse = np.sum((predictions - testing.values)** 2)\n",
    "    actual_pred = {'Predicted':predictions, 'Actual':[x[0] for x in testing.transpose().values]}\n",
    "    actual_pred = pd.DataFrame(actual_pred, index = testing.columns)\n",
    "    print(actual_pred)\n",
    "    print(f'\\nPrediction sum of squared error: {pred_sse}\\n')\n",
    "    return actual_pred['Predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of telling the PCA model how many components we wanted to keep, we decided instead to have it return the number of components it took to explain 95% of the variance of the data, which in the case of treasury yield changes was 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Explained Variance: [0.76330253 0.08974696 0.0675421  0.04663491]\n",
      "\n",
      "PCA No. Components: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the PCA model\n",
    "pca = PCA(n_components=0.95)  # Forces it to explain >99% of variance\n",
    "# Fit the PCA model\n",
    "pca.fit(training)\n",
    "print(f'PCA Explained Variance: {pca.explained_variance_ratio_}\\n')\n",
    "print(f'PCA No. Components: {pca.n_components_}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit two different regression models -- Linean and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator 0: R2 = 0.008\n",
      "\n",
      "Estimator 1: R2 = 0.043\n",
      "\n",
      "Estimator 2: R2 = 0.023\n",
      "\n",
      "Estimator 3: R2 = 0.000\n",
      "\n",
      "Sum of squared error: 67.20596541646557\n",
      "\n",
      "[1, array([-0.10059391])]\n",
      "[1, array([-0.15233152])]\n",
      "[1, array([-0.01927581])]\n",
      "[1, array([-0.0198384])]\n",
      "            Predicted    Actual\n",
      "fiveyear    -0.009274  0.027778\n",
      "onemonth     0.008572 -0.111111\n",
      "oneyear     -0.015760  0.000000\n",
      "sevenyear   -0.007291  0.075472\n",
      "sixmonth     0.049502  0.066667\n",
      "tenyear     -0.005246  0.090909\n",
      "thirtyyear  -0.002515  0.068182\n",
      "threemonth  -0.001092 -0.076923\n",
      "threeyear   -0.014679  0.000000\n",
      "twentyyear  -0.003784  0.084112\n",
      "twomonth    -0.022414 -0.090909\n",
      "twoyear     -0.019232 -0.105263\n",
      "\n",
      "Prediction sum of squared error: 0.06311788675635607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a standard OLS model\n",
    "model = LinearRegression()\n",
    "results = FitRegressionModel(pca, model, training, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator 0: R2 = 0.814\n",
      "\n",
      "Estimator 1: R2 = 0.835\n",
      "\n",
      "Estimator 2: R2 = 0.822\n",
      "\n",
      "Estimator 3: R2 = 0.816\n",
      "\n",
      "Sum of squared error: 12.488616430427138\n",
      "\n",
      "[1, array([-0.10059391])]\n",
      "[1, array([-0.15233152])]\n",
      "[1, array([-0.01927581])]\n",
      "[1, array([-0.0198384])]\n",
      "            Predicted    Actual\n",
      "fiveyear     0.075139  0.027778\n",
      "onemonth    -0.118144 -0.111111\n",
      "oneyear      0.050716  0.000000\n",
      "sevenyear    0.058816  0.075472\n",
      "sixmonth     0.226376  0.066667\n",
      "tenyear      0.065140  0.090909\n",
      "thirtyyear   0.042342  0.068182\n",
      "threemonth  -0.016886 -0.076923\n",
      "threeyear    0.069739  0.000000\n",
      "twentyyear   0.047773  0.084112\n",
      "twomonth    -0.138771 -0.090909\n",
      "twoyear      0.053890 -0.105263\n",
      "\n",
      "Prediction sum of squared error: 0.06938996854271938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Randome Forest Regression model\n",
    "model = RandomForestRegressor(random_state=0, n_estimators = 100)\n",
    "results = FitRegressionModel(pca, model, training, testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression has the highest R-squared values and the prediction SSE is approximately the same as Linear Regression, so RFR is the model we would want to use in an algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}